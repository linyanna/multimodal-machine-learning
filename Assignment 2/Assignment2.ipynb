{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read .cvs files\n",
    "df = pd.read_csv('train.csv', nrows=1) # nrows=1000\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# get target sets\n",
    "y_train = df[\"Sentiment\"].values\n",
    "y_test = test_df[\"Sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Index  Sentiment\n",
      "count    1.0        1.0\n",
      "mean     0.0        0.0\n",
      "std      NaN        NaN\n",
      "min      0.0        0.0\n",
      "25%      0.0        0.0\n",
      "50%      0.0        0.0\n",
      "75%      0.0        0.0\n",
      "max      0.0        0.0\n"
     ]
    }
   ],
   "source": [
    "# print descriptive statistics of the data, including mean, standard deviation, median, etc.\n",
    "basic_info = df.describe()\n",
    "print(basic_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data from the first 5 rows are: \n",
      "    Index  Sentiment                                               Text\n",
      "0      0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "The data from the last 5 rows are: \n",
      "    Index  Sentiment                                               Text\n",
      "0      0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n"
     ]
    }
   ],
   "source": [
    "# display the beginning X rows \n",
    "print(\"The data from the first 5 rows are: \\n\", df.head(5))\n",
    "\n",
    "# display the bottom X rows \n",
    "print(\"The data from the last 5 rows are: \\n\", df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index        0\n",
       "Sentiment    0\n",
       "Text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values; verdict = none\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linya\\AppData\\Local\\Temp\\ipykernel_13964\\1400134019.py:2: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(data=df['Sentiment'], palette='bright')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of negative and positive sentiments\n",
    "sns.histplot(data=df['Sentiment'], palette='bright')\n",
    "plt.show()\n",
    "# much more negative than positive sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\linya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\linya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\linya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(column):\n",
    "\n",
    "    # remove '@', 'http', and contractions\n",
    "    for word in column.split():\n",
    "      if word.startswith('@'):\n",
    "        column = column.replace(word, '')\n",
    "      if word.startswith('http'):\n",
    "        column = column.replace(word, '')\n",
    "      if '\\'' in word:\n",
    "        column = column.replace(word, contractions.fix(word))\n",
    "        # print (word, '->', contractions.fix(word))\n",
    "\n",
    "    # tokenize, remove punctuation, then stem\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    expanded_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "      # if tokens[i] not in stopwords.words('english'):\n",
    "      if tokens[i].isalpha():\n",
    "        expanded_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "      i += 1\n",
    "\n",
    "    return expanded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens(column):\n",
    "\n",
    "    # remove '@', 'http', and contractions\n",
    "    for word in column.split():\n",
    "      if word.startswith('@'):\n",
    "        column = column.replace(word, '')\n",
    "      if word.startswith('http'):\n",
    "        column = column.replace(word, '')\n",
    "      if '\\'' in word:\n",
    "        column = column.replace(word, contractions.fix(word))\n",
    "        # print (word, '->', contractions.fix(word))\n",
    "\n",
    "    # tokenize, remove punctuation, then stem\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    expanded_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "      # if tokens[i] not in stopwords.words('english'):\n",
    "      if tokens[i].isalpha():\n",
    "        expanded_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "      i += 1\n",
    "\n",
    "    return \" \".join(expanded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Joined Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[awww, that, is, a, bummer, you, shoulda, got,...</td>\n",
       "      <td>awww that is a bummer you shoulda got david ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                          Tokenized  \\\n",
       "0          0  [awww, that, is, a, bummer, you, shoulda, got,...   \n",
       "\n",
       "                                       Joined Tokens  \n",
       "0  awww that is a bummer you shoulda got david ca...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tokenized'] = df.apply(lambda x: tokenize(x['Text']), axis=1)\n",
    "df['Joined Tokens'] = df.apply(lambda x: join_tokens(x['Text']), axis=1)\n",
    "test_df['Tokenized'] = test_df.apply(lambda x: tokenize(x['Text']), axis=1)\n",
    "test_df['Joined Tokens'] = test_df.apply(lambda x: join_tokens(x['Text']), axis=1)\n",
    "df[['Sentiment','Tokenized','Joined Tokens']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = []\n",
    "for data in df['Joined Tokens']:\n",
    "    corpus.append(data)\n",
    "\n",
    "# Create a Count Vectorizer Object\n",
    "vectorizer  = CountVectorizer()\n",
    "bow_vector = vectorizer.fit_transform(corpus)\n",
    "\n",
    "bow_array = bow_vector.toarray()\n",
    "\n",
    "df['Bag of Words'] = bow_array.tolist()\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF*IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = []\n",
    "for data in df['Joined Tokens']:\n",
    "    corpus.append(data)\n",
    "\n",
    "# Create a Tfid Vectorizer Object\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_vector = vectorizer.fit_transform(corpus)\n",
    "\n",
    "tf_idf_array = tf_idf_vector.toarray()\n",
    "\n",
    "df['TF*IDF'] = tf_idf_array.tolist()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# word2vec/word embedding model\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "words = []\n",
    "test_words = []\n",
    "\n",
    "for data in df['Tokenized']:\n",
    "    words.append(data)\n",
    "for data in test_df['Tokenized']:\n",
    "    test_words.append(data)\n",
    "\n",
    "# CBOW model\n",
    "cbow = gensim.models.Word2Vec(words, min_count = 1,vector_size = 100, window = 5, sg=0)\n",
    "cbow_test = gensim.models.Word2Vec(test_words, min_count = 1,vector_size = 100, window = 5, sg=0)\n",
    "# Skip-gram model\n",
    "skipgram = gensim.models.Word2Vec(words, min_count = 1,vector_size = 100, window = 5, sg=1)\n",
    "skipgram_test = gensim.models.Word2Vec(test_words, min_count = 1,vector_size = 100, window = 5, sg=1)\n",
    "\n",
    "cbow_vector = []\n",
    "skipgram_vector = []\n",
    "\n",
    "for data in df['Tokenized']:\n",
    "    for word in data:\n",
    "        cbow_vector.append(cbow.wv[word])\n",
    "\n",
    "for data in df['Tokenized']:\n",
    "    for word in data:\n",
    "        skipgram_vector.append(skipgram.wv[word])\n",
    "\n",
    "# df['CBOW'] = cbow_vector.tolist()\n",
    "# df.head()\n",
    "\n",
    "print(len(cbow_vector))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build sentiment classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classifiers and metrics from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lc = LogisticRegression()\n",
    "svc = SVC(probability=True)\n",
    "nbc = GaussianNB()\n",
    "rfc = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SMOTE for Imbalanced Classification\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# oversample = SMOTE()\n",
    "# over_sampled_X_train, over_sampled_y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# lc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "# svc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "# nbc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "# rfc.fit(over_sampled_X_train, over_sampled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mPipeline([(\u001b[39m\"\u001b[39m\u001b[39mvectorizer\u001b[39m\u001b[39m\"\u001b[39m, vectorizer),  \n\u001b[0;32m      7\u001b[0m                            (\u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m, classifier)])\n\u001b[0;32m      8\u001b[0m \u001b[39m## train classifier\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model[\u001b[39m\"\u001b[39;49m\u001b[39mclassifier\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     10\u001b[0m \u001b[39m## test\u001b[39;00m\n\u001b[0;32m     11\u001b[0m X_test \u001b[39m=\u001b[39m test_df[\u001b[39m\"\u001b[39m\u001b[39mJoined Tokens\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\naive_bayes.py:749\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \n\u001b[0;32m    731\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 749\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[0;32m    750\u001b[0m _, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    752\u001b[0m labelbin \u001b[39m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32mc:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\naive_bayes.py:583\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X_y\u001b[39m(\u001b[39mself\u001b[39m, X, y, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    582\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49mreset)\n",
      "File \u001b[1;32mc:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 1]"
     ]
    }
   ],
   "source": [
    "# # Naive Bayes classifier model\n",
    "# from sklearn import naive_bayes, pipeline, metrics\n",
    "# classifier = naive_bayes.MultinomialNB()\n",
    "\n",
    "# ## pipeline\n",
    "# model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "#                            (\"classifier\", classifier)])\n",
    "# ## train classifier\n",
    "# model[\"classifier\"].fit(X_train, y_train)\n",
    "# ## test\n",
    "# X_test = test_df[\"Joined Tokens\"].values\n",
    "# predicted = model.predict(X_test)\n",
    "# predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "Auc: 0.5\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       177\n",
      "           1       0.00      0.00      0.00       182\n",
      "\n",
      "    accuracy                           0.49       359\n",
      "   macro avg       0.25      0.50      0.33       359\n",
      "weighted avg       0.24      0.49      0.33       359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\linya\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# classes = np.unique(y_test)\n",
    "# y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "# ## Accuracy, Precision, Recall\n",
    "# accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "# auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "#                             multi_class=\"ovr\")\n",
    "# print(\"Accuracy:\",  round(accuracy,2))\n",
    "# print(\"Auc:\", round(auc,2))\n",
    "# print(\"Detail:\")\n",
    "# print(metrics.classification_report(y_test, predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# # with cbow\n",
    "# train_matrix = cbow.wv.fit_transform(df['Joined Tokens'])\n",
    "# test_matrix = cbow_test.wv.fit_transform(test_df['Joined Tokens'])\n",
    "\n",
    "# X_train = train_matrix\n",
    "# X_test = test_matrix\n",
    "# y_train = df['Sentiment']\n",
    "# y_test = test_df['Sentiment']\n",
    "\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find accuracy, precision:\n",
    "# from sklearn.metrics import confusion_matrix,classification_report\n",
    "# new = np.asarray(y_test)\n",
    "# confusion_matrix(y_pred,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
