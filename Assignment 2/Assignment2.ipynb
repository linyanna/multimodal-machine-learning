{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# read .cvs files\n",
    "n = sum(1 for line in open('train.csv')) - 1 #number of records in file (excludes header)\n",
    "s = 10000 #desired sample size\n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "df = pd.read_csv('train.csv', skiprows=skip)\n",
    "\n",
    "# df = pd.read_csv('train.csv', nrows=5) # nrows=1000\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# get target sets\n",
    "y_train = df[\"Sentiment\"].to_numpy()\n",
    "y_test = test_df[\"Sentiment\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Index     Sentiment\n",
      "count  1.000000e+04  10000.000000\n",
      "mean   5.310375e+05      0.246300\n",
      "std    3.038286e+05      0.430877\n",
      "min    6.700000e+01      0.000000\n",
      "25%    2.720968e+05      0.000000\n",
      "50%    5.347295e+05      0.000000\n",
      "75%    7.963618e+05      0.000000\n",
      "max    1.048419e+06      1.000000\n"
     ]
    }
   ],
   "source": [
    "# print descriptive statistics of the data, including mean, standard deviation, median, etc.\n",
    "basic_info = df.describe()\n",
    "print(basic_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data from the first 5 rows are: \n",
      "    Index  Sentiment                                               Text\n",
      "0     67          0  Mo jobs, no money.  how in the hell is min wag...\n",
      "1     75          0            No picnic  my phone smells like citrus.\n",
      "2    161          0                     is alone downstairs...working \n",
      "3    305          0  Argh! I was suuuper sleepy an hour ago, now I'...\n",
      "4    513          0         Dammit... I need to stop buying furniture \n",
      "The data from the last 5 rows are: \n",
      "         Index  Sentiment                                               Text\n",
      "9995  1048067          1  @_MeganElizabeth haha i'm so glad you came, a ...\n",
      "9996  1048071          1                                      it's raining \n",
      "9997  1048159          1  @eyshoyy Hey girl!! I am soo happy to see you!...\n",
      "9998  1048401          1  @mattlaw hang in there sweetie....we might jus...\n",
      "9999  1048419          1  @khani Yep. I think the world is a safer place...\n"
     ]
    }
   ],
   "source": [
    "# display the beginning X rows \n",
    "print(\"The data from the first 5 rows are: \\n\", df.head(5))\n",
    "\n",
    "# display the bottom X rows \n",
    "print(\"The data from the last 5 rows are: \\n\", df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index        0\n",
       "Sentiment    0\n",
       "Text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values; verdict = none\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linya\\AppData\\Local\\Temp\\ipykernel_27612\\1400134019.py:2: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(data=df['Sentiment'], palette='bright')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of negative and positive sentiments\n",
    "sns.histplot(data=df['Sentiment'], palette='bright')\n",
    "plt.show()\n",
    "# much more negative than positive sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\linya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\linya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\linya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(column):\n",
    "\n",
    "    # remove '@', 'http', and contractions\n",
    "    for word in column.split():\n",
    "      if word.startswith('@'):\n",
    "        column = column.replace(word, '')\n",
    "      if word.startswith('http'):\n",
    "        column = column.replace(word, '')\n",
    "      if '\\'' in word:\n",
    "        column = column.replace(word, contractions.fix(word))\n",
    "        # print (word, '->', contractions.fix(word))\n",
    "\n",
    "    # tokenize, remove punctuation, then stem\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    expanded_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "      # if tokens[i] not in stopwords.words('english'):\n",
    "      if tokens[i].isalpha():\n",
    "        expanded_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "      i += 1\n",
    "\n",
    "    return expanded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens(column):\n",
    "\n",
    "    # remove '@', 'http', and contractions\n",
    "    for word in column.split():\n",
    "      if word.startswith('@'):\n",
    "        column = column.replace(word, '')\n",
    "      if word.startswith('http'):\n",
    "        column = column.replace(word, '')\n",
    "      if '\\'' in word:\n",
    "        column = column.replace(word, contractions.fix(word))\n",
    "        # print (word, '->', contractions.fix(word))\n",
    "\n",
    "    # tokenize, remove punctuation, then stem\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    expanded_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "      # if tokens[i] not in stopwords.words('english'):\n",
    "      if tokens[i].isalpha():\n",
    "        expanded_tokens.append(lemmatizer.lemmatize(tokens[i].lower()))\n",
    "      i += 1\n",
    "\n",
    "    return \" \".join(expanded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Joined Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>[haha, i, am, so, glad, you, came, a, hot, tub...</td>\n",
       "      <td>haha i am so glad you came a hot tub full of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>[it, is, raining]</td>\n",
       "      <td>it is raining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>[hey, girl, i, am, soo, happy, to, see, you, lol]</td>\n",
       "      <td>hey girl i am soo happy to see you lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>[hang, in, there, sweetie, we, might, just, pu...</td>\n",
       "      <td>hang in there sweetie we might just pull throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>[yep, i, think, the, world, is, a, safer, plac...</td>\n",
       "      <td>yep i think the world is a safer place now or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                          Tokenized  \\\n",
       "9995          1  [haha, i, am, so, glad, you, came, a, hot, tub...   \n",
       "9996          1                                  [it, is, raining]   \n",
       "9997          1  [hey, girl, i, am, soo, happy, to, see, you, lol]   \n",
       "9998          1  [hang, in, there, sweetie, we, might, just, pu...   \n",
       "9999          1  [yep, i, think, the, world, is, a, safer, plac...   \n",
       "\n",
       "                                          Joined Tokens  \n",
       "9995  haha i am so glad you came a hot tub full of b...  \n",
       "9996                                      it is raining  \n",
       "9997             hey girl i am soo happy to see you lol  \n",
       "9998  hang in there sweetie we might just pull throu...  \n",
       "9999  yep i think the world is a safer place now or ...  "
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tokenized'] = df.apply(lambda x: tokenize(x['Text']), axis=1)\n",
    "df['Joined Tokens'] = df.apply(lambda x: join_tokens(x['Text']), axis=1)\n",
    "\n",
    "test_df['Tokenized'] = test_df.apply(lambda x: tokenize(x['Text']), axis=1)\n",
    "test_df['Joined Tokens'] = test_df.apply(lambda x: join_tokens(x['Text']), axis=1)\n",
    "\n",
    "df[['Sentiment','Tokenized','Joined Tokens']].tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = []\n",
    "for data in df['Joined Tokens']:\n",
    "    corpus.append(data)\n",
    "\n",
    "# Create a Count Vectorizer Object\n",
    "vectorizer  = CountVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "bow_vector = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF*IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = []\n",
    "for data in df['Joined Tokens']:\n",
    "    corpus.append(data)\n",
    "\n",
    "# Create a Tfid Vectorizer Object\n",
    "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "tfidf_vector = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # word2vec/word embedding model\n",
    "# import gensim\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# words = []\n",
    "# test_words = []\n",
    "\n",
    "# for data in df['Tokenized']:\n",
    "#     words.append(data)\n",
    "# for data in test_df['Tokenized']:\n",
    "#     test_words.append(data)\n",
    "\n",
    "# # CBOW model\n",
    "# cbow = gensim.models.Word2Vec(words, min_count = 1,vector_size = 100, window = 5, sg=0)\n",
    "# # Skip-gram model\n",
    "# skipgram = gensim.models.Word2Vec(words, min_count = 1,vector_size = 100, window = 5, sg=1)\n",
    "\n",
    "# cbow_vector = []\n",
    "# skipgram_vector = []\n",
    "\n",
    "# for data in df['Tokenized']:\n",
    "#     for word in data:\n",
    "#         cbow_vector.append(cbow.wv[word])\n",
    "#     # cbow_vector.append(function_text_2_vec(data))\n",
    "\n",
    "# for data in df['Tokenized']:\n",
    "#     for word in data:\n",
    "#         skipgram_vector.append(skipgram.wv[word])\n",
    "\n",
    "# print(np.array(cbow_vector).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying something else for w2v\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [sentence for sentence in df['Joined Tokens']]\n",
    "w2v_model = Word2Vec(sentences, vector_size=1000, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(1000)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build sentiment classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classifiers and metrics from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lc = LogisticRegression()\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svc = SVC(probability=True)\n",
    "nbc = GaussianNB()\n",
    "rfc = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SMOTE for Imbalanced Classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_and_predict_models():\n",
    "    y = df['Sentiment'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    over_sampled_X_train, X_test, over_sampled_y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    oversample = SMOTE()\n",
    "    over_sampled_X_train, over_sampled_y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    lc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "    neigh.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "    svc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "    nbc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "    rfc.fit(over_sampled_X_train, over_sampled_y_train)\n",
    "\n",
    "    y_lc_predicted = lc.predict(X_test)\n",
    "    y_lc_pred_proba = lc.predict_proba(X_test)\n",
    "\n",
    "    y_knn_predicted = neigh.predict(X_test)\n",
    "    y_knn_pred_proba = neigh.predict_proba(X_test)\n",
    "\n",
    "    y_svc_predicted = svc.predict(X_test)\n",
    "    y_svc_pred_proba = svc.predict_proba(X_test)\n",
    "\n",
    "    y_nbc_predicted = nbc.predict(X_test)\n",
    "    y_nbc_pred_proba = nbc.predict_proba(X_test)\n",
    "\n",
    "    y_rfc_predicted = rfc.predict(X_test)\n",
    "    y_rfc_pred_proba = rfc.predict_proba(X_test)\n",
    "\n",
    "    print('Logistic Regression:\\n', classification_report(y_test, y_lc_predicted))\n",
    "    print('K Nearest Neighbor:\\n', classification_report(y_test, y_knn_predicted))\n",
    "    print('Support Vector Machine:\\n', classification_report(y_test, y_svc_predicted))\n",
    "    print('Naive Bayes Classification:\\n', classification_report(y_test, y_nbc_predicted))\n",
    "    print('Random Forest classification:\\n', classification_report(y_test, y_rfc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words: \n",
      "\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1511\n",
      "           1       0.50      0.66      0.57       489\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.69      0.73      0.70      2000\n",
      "weighted avg       0.79      0.76      0.77      2000\n",
      "\n",
      "K Nearest Neighbor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.55      0.67      1511\n",
      "           1       0.33      0.67      0.44       489\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.58      0.61      0.55      2000\n",
      "weighted avg       0.71      0.58      0.61      2000\n",
      "\n",
      "Support Vector Machine:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1511\n",
      "           1       0.54      0.46      0.50       489\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.69      0.67      0.67      2000\n",
      "weighted avg       0.76      0.77      0.77      2000\n",
      "\n",
      "Naive Bayes Classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78      1511\n",
      "           1       0.40      0.57      0.47       489\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.62      0.65      0.62      2000\n",
      "weighted avg       0.73      0.69      0.70      2000\n",
      "\n",
      "Random Forest classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      1511\n",
      "           1       0.50      0.42      0.45       489\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.66      0.64      0.65      2000\n",
      "weighted avg       0.74      0.75      0.75      2000\n",
      "\n",
      "TF*IDF: \n",
      "\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1511\n",
      "           1       0.51      0.63      0.57       489\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.69      0.72      0.70      2000\n",
      "weighted avg       0.78      0.76      0.77      2000\n",
      "\n",
      "K Nearest Neighbor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.20      0.32      1511\n",
      "           1       0.26      0.90      0.41       489\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.56      0.55      0.36      2000\n",
      "weighted avg       0.71      0.37      0.34      2000\n",
      "\n",
      "Support Vector Machine:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      1511\n",
      "           1       0.65      0.35      0.46       489\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.73      0.65      0.67      2000\n",
      "weighted avg       0.78      0.80      0.77      2000\n",
      "\n",
      "Naive Bayes Classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.75      1511\n",
      "           1       0.39      0.70      0.50       489\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.63      0.67      0.62      2000\n",
      "weighted avg       0.75      0.66      0.69      2000\n",
      "\n",
      "Random Forest classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1511\n",
      "           1       0.57      0.39      0.46       489\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.70      0.65      0.66      2000\n",
      "weighted avg       0.76      0.78      0.76      2000\n",
      "\n",
      "Word2Vec: \n",
      "\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.49      0.61      1511\n",
      "           1       0.29      0.63      0.40       489\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.55      0.56      0.50      2000\n",
      "weighted avg       0.68      0.53      0.56      2000\n",
      "\n",
      "K Nearest Neighbor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      1511\n",
      "           1       0.28      0.22      0.25       489\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.64      0.67      0.66      2000\n",
      "\n",
      "Support Vector Machine:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.51      0.63      1511\n",
      "           1       0.30      0.63      0.40       489\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.55      0.57      0.52      2000\n",
      "weighted avg       0.69      0.54      0.57      2000\n",
      "\n",
      "Naive Bayes Classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.48      0.60      1511\n",
      "           1       0.29      0.65      0.40       489\n",
      "\n",
      "    accuracy                           0.52      2000\n",
      "   macro avg       0.55      0.57      0.50      2000\n",
      "weighted avg       0.68      0.52      0.55      2000\n",
      "\n",
      "Random Forest classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.45      0.58      1511\n",
      "           1       0.29      0.69      0.40       489\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.55      0.57      0.49      2000\n",
      "weighted avg       0.69      0.51      0.54      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words\n",
    "print('Bag of Words: \\n')\n",
    "X = bow_vector.toarray()\n",
    "train_and_predict_models()\n",
    "\n",
    "# TF*IDF\n",
    "print('TF*IDF: \\n')\n",
    "X = tfidf_vector.toarray()\n",
    "train_and_predict_models()\n",
    "\n",
    "# Word2Vec\n",
    "print('Word2Vec: \\n')\n",
    "# X = np.array(cbow_vector)\n",
    "# train_and_predict_models()\n",
    "X = np.array([vectorize(sentence) for sentence in df['Joined Tokens']])\n",
    "train_and_predict_models()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
